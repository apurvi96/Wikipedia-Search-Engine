{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords',quiet=\"True\")\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.porter import *\n",
    "import sys\n",
    "# from nltk.stem.snowball import SnowballStemmer\n",
    "import Stemmer \n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "globalDictionary={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDictionary(indexPath):\n",
    "    global globalDictionary\n",
    "    with open(indexPath, \"r\") as infile:\n",
    "        for line in infile:\n",
    "            line=line.strip()\n",
    "            wordList=line.split(\":\")\n",
    "            globalDictionary[wordList[0]]=wordList[1]\n",
    "    infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handlePlainQuery(query):\n",
    "    global globalDictionary\n",
    "    words=query.split(\" \")\n",
    "    words= [w.casefold() for w in words]\n",
    "    #stemming\n",
    "    stemmer=Stemmer.Stemmer('english')\n",
    "    words= [stemmer.stemWord(w) for w in words]\n",
    "    for w in words:\n",
    "        if w in globalDictionary:\n",
    "            print(w,\": \",globalDictionary[w])\n",
    "        else:\n",
    "            print(w,\": []\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handleFieldQuery(query):\n",
    "    global globalDictionary\n",
    "    words=query.split(\" \")\n",
    "    currTag=\"\"\n",
    "    stemmer=Stemmer.Stemmer('english')\n",
    "    for w in words:\n",
    "        if \":\" in w:\n",
    "            split_word=w.split(\":\")\n",
    "            currTag=\"#\"+split_word[0]\n",
    "            w=split_word[1]\n",
    "        w=w.casefold()\n",
    "        w=stemmer.stemWord(w)\n",
    "        if w in globalDictionary:\n",
    "            if currTag in globalDictionary[w]:\n",
    "                print(w,\": \",globalDictionary[w])\n",
    "            else:\n",
    "                print(w,\": []\")\n",
    "        else:\n",
    "            print(w,\": []\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anarch :  d2#t1#b218#c1#l1\n",
      "accessiblecomput :  d1#t1\n",
      "swqwe : []\n",
      "shell :  d3#b1|d4#b1|d5#b1|d6#b1|d7#b1|d8#b1|d9#b1|d10#b1\n",
      "1864 :  d2#b3\n",
      "17 : []\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    indexPath=\"./output/indexfile1.txt\"\n",
    "#     indexPath=sys.argv[1]\n",
    "    query=\"Anarch AccessibleComputing swqwe Shell 1864 17\"\n",
    "#     query=\"t:Anarch AccessibleComputing swqwe Shell b:1864 17\"\n",
    "#     query=sys.argv[2]\n",
    "    createDictionary(indexPath)\n",
    "    queryType=\"plain\"\n",
    "    if \":\" in query:\n",
    "        queryType=\"field\"\n",
    "    \n",
    "    if queryType==\"plain\":\n",
    "        handlePlainQuery(query)\n",
    "    \n",
    "    elif queryType==\"field\":\n",
    "        handleFieldQuery(query)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
